
\section{Related Work}

%Throughout the years, there have been increasing efforts towards code-size optimizations.
%Most of the classic optimizations try to find semantically equivalent programs
%that require fewer instructions to execute, such as dead code elimination,
%common subexpression elimination, and others~\cite{cocke70,massalin87,knoop94}.
Compiler optimizations for code-size reduction exist since the very beginning
of optimizing compilers.
These optimizations can be divided in two main categories:
those that replace a piece of code by a smaller but semantically equivalent code,
changing the instructions and operations performed~\cite{massalin87,tanenbaum82};
and those that remove or combine redundant code~\cite{cocke70,knoop94,ernst97,
                                              cooper99,debray00,chen03,loki04}.
Function merging falls in the latter category.

\subsection{Function-Merging Techniques}

Google developed an optimization for the \textit{gold} linker that merges
identical functions on a bit-level~\cite{tallam10,kwan12}.
After placing each function in a separate ELF section, they identify functions
sections that have their \textit{text} bit-identical and also their
relocations point to identical sections.
Similar machine-level implementations are also offered by other production compilers
and linkers, such as MSVC~\cite{msvc-icf}.
%A simpler version of this optimization was also offered by the MSVC linker~\cite{msvc-icf};

This machine-level solution is target-dependent and needs to be adapted for every back-end.
A similar optimization for merging identical functions %, but implemented at the IR level,
is offered at the IR level by both GCC and LLVM~\cite{llvm-fm,livska14}.
%In Section~\ref{sec:background}, we presented a detailed description of the
%related work on function-merging, including the state-of-the-art~\cite{edler14}.
%The function merging optimization currently offered by GCC and LLVM is
%only able to merge identical functions~\cite{llvm-fm,livska14}.
This optimization is only flexible enough to accommodate simple type mismatches
provided they can be bitcast in a lossless way.
%Similarly to the technique proposed by Edler von Koch~et~al.~\cite{edler14},
%LLVM's optimization also exploits structural similarity among functions.
%However, the current implementation does not allow instructions to differ in
%their opcodes or in the number and type of their input operands.
%Although very restrictive, this optimization guarantees that any pair of
%mergeable functions will result in code size reduction with no performance
%overhead.
%Its simplicity also benefits compilation time, as the actual merge operation
%is trivial.
Its simplicity allows for an efficient exploration approach based on computing
the hash of the functions and then using a tree structure to group equivalent
functions based on their hash values.

The state-of-the-art function-merging technique, proposed by Edler von
Koch~et~al.~\cite{edler14}, exploits structural similarity among functions.
Their optimization is able to merge similar functions that are not necessarily
identical.
Two functions are structurally similar if both their function types are equivalent
and their CFGs isomorphic.
Two function types are equivalent if they agree in the number, order, and types
of their parameters as well as
their return types, linkage type, and other compiler-specific properties.
In addition to the structural similarity of the functions, their technique also
requires that corresponding basic blocks have exactly the same number of instructions
and that corresponding instructions must have equivalent resulting types.
% but may differ in their opcodes or in the number and type of their input operands.
Mergeable functions are only allowed to differ in corresponding instructions,
where they can differ in their opcodes or in the number and type of their input operands.
%The only differences that are actually allowed is that
%corresponding instructions can 
%differ in their opcodes or in the number and type of their input operands.

%If two corresponding instructions have different opcodes, they split the basic
%block and insert a switch branch to select which instruction to execute
%depending on a function identifier.

Because the state-of-the-art is limited to functions with identical CFGs
and function types, once it merges a pair of functions, a third
\textit{similar} function cannot be merged into the resulting merged function
since they will differ in both CFGs and their lists of parameters.
Due to this limiting factor, the state-of-the-art has to first collect all
mergeable functions and merge them simultaneously.

The state-of-the-art algorithm iterates simultaneously over corresponding basic
blocks in the set functions being merged, as they have isomorphic CFGs.
For every basic block, if their corresponding instructions have different opcodes,
they split the basic block and insert a switch branch to select which instruction
to execute depending on a function identifier.
Because these instructions have equivalent resulting types, their results can be
merged using a phi-operator, which can then be used transparently as operands
by other instructions.

Although the state-of-the-art technique improves over LLVM's identical function merging, it is
still unnecessarily limited. In Section~\ref{sec:motivation}, we showed examples of very similar
real functions where the state-of-the-art fails to merge. Our approach addresses such limitations
improving on the state-of-the-art across the board.

\subsection{Code Factoring}

%Function merging and code factoring are different techniques for solving the
%same fundamental problem of duplicated code.
Code factoring is a related technique that addresses the same fundamental
problem of duplicated code in a different way.
%While the former works by merging similar functions, the latter works by
%factoring out duplicated code~\cite{loki04}.
%Instead of merging similar functions, code factoring works by factoring out
%duplicated code into separate functions~\cite{loki04}.
Code factoring can be applied at different levels of the program~\cite{loki04}.
Local factoring, also known as local code motion, moves identical instructions
from multiple basic blocks to either their common predecessor or successor,
whenever valid~\cite{knoop94,briggs94,loki04}.
Procedural abstraction %(or outlining)
finds identical code
that can be extracted into a separate function, replacing all replicated
occurrences with a function call~\cite{loki04,dreweke07}.

Procedural abstraction differs from function merging as it usually works on
single basic blocks or single-entry single-exit regions.
Moreover, it only works for identical segments of code, and every identical
segment of code is extracted into a separately new function.
Function merging, on the other hand, works on whole functions, which can be
identical or just partially similar, producing a single merged function.

However, all these techniques are orthogonal to the proposed optimization and
could complement each other at different stages of the compilation pipeline.

\subsection{Other Applications of Code Similarity}

Code similarity has also been used in other compiler optimizations or tools for
software development and maintenance.
In this section, we describe some of these applications.

Coutinho~et~al.~\cite{coutinho11} proposed an optimization that uses instruction
alignment to reduce divergent code for GPU.
They are able to fuse divergent branches that contain single basic blocks,
improving GPU utilization.
%reducing idle cores.

Similarly, analogous algorithms have also been suggested to identify the
differences between two programs, helping developers with source-code
management and maintenance~\cite{yang91,miller85}.
These techniques are applied in tools for source-code management, such as
\textit{diff} command~\cite{miller85}.

Similar techniques have also been applied to code editors and IDEs~\cite{toomim04,sajnani16}.
For example,
SourcererCC~\cite{sajnani16} detects possible clones, at the source level, by
dividing the programs into a set of code blocks where each code block is itself
represented by a bag-of-tokens, i.e., a set of tokens and their frequencies.
Tokens are keywords, literals, and identifiers, but no operators.
Code blocks are considered clones if their degree of similarity is higher than
a given threshold.
In order to reduce the number of blocks compared, candidate blocks are filtered
based on a few of their tokens where at least one must match.

Our ranking mechanism uses an approach similar to SourcererCC, where we use
opcode frequencies and type frequencies to determine if two functions are
likely to have similar code.
However, we need a precise and effective analysis of code similarity when
performing the actual merge.
To this end, we use a sequence alignment technique.

