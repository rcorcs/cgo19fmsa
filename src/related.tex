
\section{Related Work}

Throughout the years, there have been increasing efforts towards code-size
optimizations.
%Most of the classic optimizations try to find semantically equivalent programs
%that require fewer instructions to execute, such as dead code elimination,
%common subexpression elimination, and others~\cite{cocke70,massalin87,knoop94}.
Compiler optimizations for code-size reduction exist since the very beginning
of optimizing compilers.
These optimizations can be divided in two main categories:
those that replace a piece of code by a smaller but semantically equivalent code,
changing the instructions and operations performed~\cite{massalin87,tanenbaum82};
and those that remove or combine redundant code~\cite{cocke70,knoop94,ernst97,
                                              cooper99,debray00,chen03,loki04}.
One optimization from this second category is function merging.

\subsection{Existing Function-Merging Techniques}

Google developed an optimization for the \textit{gold} linker that merges
identical functions on a bit-level~\cite{tallam10,kwan12}.
After placing each function in a separate ELF section, they identify function
sections that have their \textit{text} section bit-identical and also their
relocations point to identical sections.
Similar machine-level implementations are also offered by other production compilers
and linkers, such as MSVC~\cite{msvc-icf}.
%A simpler version of this optimization was also offered by the MSVC linker~\cite{msvc-icf};

However, this machine-level solution is target-dependent and therefore needs to be
adapted for every different back-end.
A similar optimization for merging identical functions %, but implemented at the IR level,
is offered at the IR level by both GCC and LLVM~\cite{llvm-fm,livska14}.
%In Section~\ref{sec:background}, we presented a detailed description of the
%related work on function-merging, including the state-of-the-art~\cite{edler14}.
%The function merging optimization currently offered by GCC and LLVM is
%only able to merge identical functions~\cite{llvm-fm,livska14}.
This optimization is only flexible enough to accommodate simple type mismatches
provided they can be bitcast in a lossless way.
%Similarly to the technique proposed by Edler von Koch~et~al.~\cite{edler14},
%LLVM's optimization also exploits structural similarity among functions.
%However, the current implementation does not allow instructions to differ in
%their opcodes or in the number and type of their input operands.
%Although very restrictive, this optimization guarantees that any pair of
%mergeable functions will result in code size reduction with no performance
%overhead.
%Its simplicity also benefits compilation time, as the actual merge operation
%is trivial.
Its simplicity allows for an efficient exploration approach based on computing
the hash of the functions and then using a tree structure to group equivalent
functions based on their hash values.

The state-of-the-art function-merging technique, proposed by Edler von
Koch~et~al.~\cite{edler14}, exploits structural similarity among functions.
Their optimization is able to merge similar functions that are not necessarily
identical.
%It is a fast but very limited technique which is able to merge only nearly
%identical functions.
Two functions are structurally similar if both their function types and
isomorphic CFGs.
%Functions have equivalent signatures
Two function types are equivalent
if they agree in the number, order, and types of their parameters as well as
their return types, linkage type, and other compiler-specific properties.
%CFGs are equivalent if and only if they are isomorphic graphs, i.e., there is a
%directed edge-preserving bijection between the vertex-set of the two graphs.
In addition to the structural similarity among functions, they also require
that corresponding basic blocks of isomorphic CFGs have exactly the same number
of instructions and that corresponding instructions must have equivalent
resulting types but may differ in their opcodes or in the number and type of
their input operands.
If two corresponding instructions have different opcodes, they split the basic
block and insert a switch branch to select which instruction to execute
depending on a new integer parameter that represents the function identifier.
%Two instructions have equivalent resulting types if they have exactly
%the same type or if they can be bitcasted in a losslessly way.

Because the state-of-the-art is limited to merge functions with identical CFGs
and function types, once it merges a pair of functions, a third
\textit{similar} function cannot be merged with the resulting merged function
since they will differ in both CFGs and their lists of parameters.
Due to this limiting factor, the state-of-the-art has to first collect all
mergeable functions and merge them simultaneously.

Although the state-of-the-art technique improves over LLVM's identical
function merging, all existing techniques still have several limitations to
their ability of merging functions.
%regarding which functions they are able to merge.
%In this paper, we propose a novel function-merging technique that is
%fundamentally different from the existing ones, addressing most of their major
%limitations.
In Section~\ref{sec:motivation}, we showed examples of real functions where the
existing techniques fail to merge and the scale of the missed opportunity.

\subsection{Code Factoring}

%Function merging and code factoring are different techniques for solving the
%same fundamental problem of duplicated code.
Code factoring is a related technique that addresses the same fundamental
problem of duplicated code in a different way.
%While the former works by merging similar functions, the latter works by
%factoring out duplicated code~\cite{loki04}.
%Instead of merging similar functions, code factoring works by factoring out
%duplicated code into separate functions~\cite{loki04}.
Code factoring can be applied at different levels of the program~\cite{loki04}.
Local factoring, also known as local code motion, moves identical instructions
from multiple basic blocks to either their common predecessor or successor,
whenever valid~\cite{knoop94,briggs94,loki04}.
Procedural abstraction (or outlining) finds identical code
that can be extracted into a separate function, replacing all replicated
occurrences with a function call~\cite{loki04,dreweke07}.

Procedural abstraction differs from function merging as it usually works on
single basic blocks or single-entry single-exit regions.
Moreover, it only works for identical segments of code, and every identical
segment of code is extracted into a separately new function.
Function merging, on the other hand, works on whole functions, which can be
identical or just partially similar, producing a single merged function.

However, all these techniques are orthogonal to the proposed optimization and
could complement each other at different stages of the compilation pipeline.
