\section{Introduction}
\label{sec:introduction}

In recent years, resource-constrained devices are becoming increasingly
important. Application binaries for these devices often reach several megabytes
in size, turning memory size into a limiting factor~\cite{plaza18}. Just adding more
memory is not always a viable option. Highly integrated System-on-Chips are
common in this market and their memories typically occupy the largest fraction
of the chip area, contributing most of the overall cost. Even small
increases in memory area translate directly to equivalent increases in cost,
which lead to enormous levels of lost profit in large scales~\cite{edler10}.

In such constrained scenarios, reducing the code size is essential~\cite{schultz03,varma04,sehgal12,keoh14,auler17}.
Unfortunately, production compilers offer little help beyond dead-code
elimination or merging identical functions~\cite{tallam10,kwan12,livska14}.
Developers might have more luck just removing functionality from their
libraries~\cite{keoh14} or hand-optimizing their code~\cite{weaver09}.

%Furthermore, the rise of the Internet of Things (IoT) depends heavily on tiny and efficient devices.
%Some of these devices can have as little as only a few kilobytes of
%memory~\cite{yelamarthi17,plaza18}.
%At the same time, low-end devices have been playing an important role in driving
%innovation in developing countries~\cite{hart02,etzo10}.
%As a result, there is an increasing focus on the development of programs
%tailored for these low-end devices with limited memory sizes~\cite{androidGo,hahm16}.

Function merging reduces replicated code by combining multiple identical
functions into a single one. 
Although a simple and intuitive concept, it is crucial for making high-level
abstractions usable, when they introduce duplicate code~\cite{tallam10,kwan12}.
For example, some C++ ABIs may end up creating multiple identical constructors
and destructors of a class to use in different contexts~\cite{kwan12} and C++
templates replicate code for different specializations~\cite{tallam10,livska14}.
More advanced approaches~\cite{edler14} have extended this idea into
merging non-identical functions by leveraging structural similarity. Functions
with identical control-flow graphs (CFGs) and only small differences within
corresponding basic blocks are merged into a single function that maintains
the semantics of the original functions. This is particularly important for
handling specialized template functions with small differences in their
compiled form.

While an improvement, even the state-of-the-art often fails to produce any
noticeable code size reduction. In this paper, we introduce a novel way to merge
functions that overcomes the major limitations of the state-of-the-art. Our
insight was that the weak results of existing function merging implementations
are not due to the lack of duplicate code but due to the rigid, overly restrictive
algorithms they use to find duplicates.

Our approach is based upon the concept of sequence alignment, developed in
bioinformatics for identifying functional or evolutionary relationships between
different DNA or RNA sequences. Similarly, we use sequence alignment to find
areas of functional similarity in arbitrary function pairs. Aligned segments
with equivalent code are merged. The remaining segments where the two functions
differ are added to the new function too but have their code guarded by a
function identifier. This approach leads to significant code size reduction,
more than three times better than the state-of-the-art can achieve.

Applying sequence alignment to all pairs of functions is prohibitively expensive
even for medium sized programs. To counter this, our technique is integrated with
a ranking-based exploration mechanism that efficiently focuses the search to the most
promising pairs of function. %\todo{whats interesting about this ranking?}.
As a result, we achieve our code size savings while introducing little compilation-time
overhead.

Compared to identical function merging, we introduce extra code to be executed,
namely the code that chooses dissimilar sequences in merged functions. A naive
implementation could easily hurt performance, e.g by merging two hot functions
with only few similarities. Our implementation avoids this by incorporating
profiling information to identify hot code blocks and effectively disable code
size optimizations for them. %\todo{the rest is WiP}.

Our function-merging technique is able to merge any two functions, i.e., it
provides the following improvements over the state-of-the-art:
\begin{itemize}[noitemsep,topsep=0pt]
  \item It is capable of merging functions with different signature, i.e.,
  different return type or list of parameters.
  \item It is capable of merging CFGs with different structures.
  \item While the state-of-the-art is able to only merge instructions within
  corresponding basic blocks in structurally identical CFGs,
  our technique can merge instructions spanning across multiple basic blocks.
\end{itemize}
In order to focus the optimization on promising pairs of functions,
our technique is integrated with a ranking-based exploration mechanism.
As a result, our optimization is more than three times better than the
state-of-the-art for reducing code size with little compilation-time overhead.
Our optimization is able to reduce size of the compiled programs by up to
22\% over the already highly optimized baseline, with an average code-size
reduction of about 5.6\%.
These optimization can be carried on with little or no significant impact on
performance, especially when aided by profiling information.
%Moreover, aided by profiling information, these optimization can be carried on
%without any significant impact on performance.
%We also propose a ranking-based exploration mechanism so that we can focus
%the optimization on promising pairs of functions.
Our prototype introduces an average overhead of only 20\% in compilation time.



%Most of the classic optimizations try to find semantically equivalent programs
%that require fewer instructions to execute, such as dead code elimination,
%common subexpression elimination, and others~\cite{cocke70,massalin87,knoop94}.
%Although initially motivated by performance, these optimizations achieve better
%performance by focusing on code-size reduction.

%However, we distinguish the optimizations that focus on code-size reduction in
%two main categories:
%  (1) optimizations that find a smaller number instructions
%  that are required to execute in order to perform the same computation, e.g.,
%  common subexpression elimination, superoptimization, peephole optimization,
%  etc.~\cite{cocke70,massalin87,cooper99,tanenbaum82}.
%  (2) optimizations that change the representation of the same sequence of
%  instructions in a more compact manner, e.g., code compression, 
%  code factoring, function merging,
%  etc.~\cite{ernst97,debray00,chen03,loki04,edler14}.

%Code-size reduction is especially important for embedded or
%low-end devices~\cite{schultz03,varma04,sehgal12,keoh14,auler17}, as some
%of these devices can have only a few kilobytes of memory~\cite{plaza18}.

%However, even in high-end devices, on-chip memory is very limited in size, and
%if well utilized can result in good performance. 
%Moreover, there has been many attempts towards high-performance computation at
%low costs~\cite{phelan03}.


%For example, Android Go is a tailored Android distribution for low-end devices
%that has a major focus on code size reduction for both the operating system itself
%and the applications, suitable for devices with 1~GiB
%of RAM or less~\cite{androidGo}.

%However, we argue that even when storage and memory resources are abundant,
%compilers should ideally heavily optimize cold code for size reduction while
%optimizing hot code for performance.
%This idea is evident in many attempts, in both research and industry, of
%performing high-performance computation at low cost.

%\cite{weaver09}
%\cite{steenkiste89}
%\cite{zmily06}

%Differently from most of the optimizations that perform code-size
%reduction~\cite{cocke70,massalin87,cooper99}, which reduces the number of
%instructions that need to be \textit{executed} in order to perform the same
%computation, there are other optimizations that perform code-size
%reduction by reducing the number of instructions necessary to \textit{represent}
%the same computation.
%Note that in the second case, the actual number of instructions executed
%may not differ or, sometimes, even increase.
%One such optimization is function merging, which 


